{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e9d5519",
   "metadata": {},
   "source": [
    "# Hybrid Forgery Testing & Evaluation\n",
    "This notebook is dedicated to evaluating trained Hybrid Forgery Detection models. It covers loading checkpoints, computing metrics, visualizing qualitative samples, and single image inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43399a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "try:\n",
    "    import pandas as pd\n",
    "except ImportError:\n",
    "    pd = None\n",
    "try:\n",
    "    from huggingface_hub import snapshot_download\n",
    "except ImportError:\n",
    "    snapshot_download = None\n",
    "try:\n",
    "    from google.colab import userdata\n",
    "except ImportError:\n",
    "    userdata = None\n",
    "def running_in_colab():\n",
    "    try:\n",
    "        import google.colab\n",
    "        return True\n",
    "    except ImportError:\n",
    "        return False\n",
    "USE_COLAB = running_in_colab()\n",
    "if USE_COLAB:\n",
    "    print(\"Colab environment detected.\")\n",
    "else:\n",
    "    print(\"Running in local environment.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0104be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "DRIVE_BASE_DIR = \"/content/drive/MyDrive/LIFD\"\n",
    "if USE_COLAB:\n",
    "    try:\n",
    "        from google.colab import drive\n",
    "        drive.mount('/content/drive')\n",
    "    except ModuleNotFoundError as exc:\n",
    "        raise RuntimeError(\"google.colab is not available. Set USE_COLAB=False to bypass Drive mounting.\") from exc\n",
    "else:\n",
    "    DRIVE_BASE_DIR = \".\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed2cb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = Path(DRIVE_BASE_DIR)\n",
    "os.environ.setdefault(\"PYTORCH_CUDA_ALLOC_CONF\", \"expandable_segments:True\")\n",
    "CPU_COUNT = os.cpu_count() or 4\n",
    "GPU_AVAILABLE = torch.cuda.is_available()\n",
    "if GPU_AVAILABLE:\n",
    "    try:\n",
    "        _gpu_props = torch.cuda.get_device_properties(0)\n",
    "        GPU_TOTAL_MEM_GB = _gpu_props.total_memory / (1024 ** 3)\n",
    "    except Exception:\n",
    "        GPU_TOTAL_MEM_GB = None\n",
    "else:\n",
    "    GPU_TOTAL_MEM_GB = None\n",
    "PERFORMANCE_MODE = \"throughput\" if GPU_AVAILABLE and CPU_COUNT >= 8 else (\"balanced\" if CPU_COUNT >= 6 else \"fast\")\n",
    "if PERFORMANCE_MODE == \"throughput\":\n",
    "    DATA_WORKERS = max(4, min(8, CPU_COUNT - 1))\n",
    "    TRAIN_BATCH_SIZE = 32 if GPU_AVAILABLE else 8\n",
    "    PREFETCH_FACTOR = 6 if DATA_WORKERS > 0 else None\n",
    "elif PERFORMANCE_MODE == \"balanced\":\n",
    "    DATA_WORKERS = max(3, min(6, CPU_COUNT - 1))\n",
    "    TRAIN_BATCH_SIZE = 24 if GPU_AVAILABLE else 8\n",
    "    PREFETCH_FACTOR = 4 if DATA_WORKERS > 0 else None\n",
    "else:\n",
    "    half_cpus = max(1, CPU_COUNT // 2)\n",
    "    DATA_WORKERS = max(1, min(4, half_cpus))\n",
    "    TRAIN_BATCH_SIZE = 16 if GPU_AVAILABLE else 8\n",
    "    PREFETCH_FACTOR = 2 if DATA_WORKERS > 0 else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ac01b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_ROOT = Path(\"/content/data\") if USE_COLAB else Path(\"prepared\") / \"CASIA2\"\n",
    "DATASET_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "HF_REPO_ID = \"juhenes/lifd\"\n",
    "HF_REVISION = os.environ.get(\"HF_DATA_REVISION\", \"main\")\n",
    "HF_TOKEN = userdata.get(\"HUGGINGFACE_TOKEN\") if userdata is not None else os.environ.get(\"HUGGINGFACE_TOKEN\")\n",
    "MANIFEST_FILENAME = \"manifest.parquet\"\n",
    "def _locate_manifest_root(base: Path):\n",
    "    candidates = [base, base / \"CASIA2\"]\n",
    "    for candidate in candidates:\n",
    "        manifest_path = candidate / MANIFEST_FILENAME\n",
    "        if manifest_path.exists():\n",
    "            return candidate\n",
    "    return None\n",
    "def ensure_dataset_ready(force_sync: bool = False) -> Path:\n",
    "    if not force_sync:\n",
    "        local_root = _locate_manifest_root(DATASET_ROOT)\n",
    "        if local_root is not None:\n",
    "            return local_root\n",
    "    if snapshot_download is None:\n",
    "        raise ImportError(\"huggingface_hub is not installed.\")\n",
    "    snapshot_dir = Path(snapshot_download(\n",
    "        repo_id=HF_REPO_ID,\n",
    "        revision=HF_REVISION,\n",
    "        token=HF_TOKEN,\n",
    "        repo_type=\"dataset\",\n",
    "))\n",
    "    resolved_snapshot = _locate_manifest_root(snapshot_dir)\n",
    "    if resolved_snapshot is None:\n",
    "        raise FileNotFoundError(\n",
    "            f\"Downloaded dataset at {snapshot_dir} does not contain {MANIFEST_FILENAME}.\"\n",
    "        )\n",
    "    return resolved_snapshot\n",
    "DATASET_ROOT = ensure_dataset_ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558d4598",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import islice\n",
    "def inspect_prepared_dataset(root: Path, split: str = \"test\", preview: int = 5):\n",
    "    root = Path(root)\n",
    "    print(f\"Resolved DATASET_ROOT: {root}\")\n",
    "    manifest_path = root / \"manifest.parquet\"\n",
    "    print(f\"Manifest present: {manifest_path.exists()} ({manifest_path})\")\n",
    "    if not manifest_path.exists():\n",
    "        return\n",
    "    try:\n",
    "        import pandas as pd\n",
    "        manifest_df = pd.read_parquet(manifest_path)\n",
    "        print(f\"Manifest rows: {len(manifest_df):,}\")\n",
    "        label_counts = manifest_df.groupby([\"split\"]).size().to_dict()\n",
    "        print(\"Rows per split:\", label_counts)\n",
    "    except Exception as exc:\n",
    "        print(f\"Manifest read failed: {exc}\")\n",
    "    split_dir = root / split\n",
    "    print(f\"Split directory exists: {split_dir.exists()} ({split_dir})\")\n",
    "    if not split_dir.exists():\n",
    "        return\n",
    "    shards = sorted(split_dir.glob(\"*.tar\"))\n",
    "    print(f\"Found {len(shards)} shard files under {split_dir}\")\n",
    "    for shard in islice(shards, preview):\n",
    "        print(f\" - {shard} | exists={shard.exists()} | size={shard.stat().st_size if shard.exists() else 'missing'}\")\n",
    "    missing = [str(p) for p in shards if not p.exists()]\n",
    "    if missing:\n",
    "        print(\"Missing shards:\", missing[:5], \"...\")\n",
    "inspect_prepared_dataset(DATASET_ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20303e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import TrainConfig\n",
    "from model.hybrid_forgery_detector import HybridForgeryConfig\n",
    "from evaluation.eval_utils import (\n",
    "    collect_visual_samples,\n",
    "    evaluate_split,\n",
    "    load_model_from_checkpoint,\n",
    " )\n",
    "checkpoint_dir = BASE_PATH / \"checkpoints\"\n",
    "checkpoint_path = checkpoint_dir / \"best.pt\"\n",
    "eval_device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd74deab",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, trained_config = load_model_from_checkpoint(checkpoint_path, device=eval_device)\n",
    "auto_threshold = True\n",
    "threshold_candidates = trained_config.eval_thresholds or [0.5]\n",
    "threshold_metric = \"f1\"\n",
    "evaluation_split = \"test\"\n",
    "max_eval_batches = None\n",
    "evaluation_summary = evaluate_split(\n",
    "    model=model,\n",
    "    train_config=trained_config,\n",
    "    split=evaluation_split,\n",
    "    batch_size=trained_config.batch_size,\n",
    "    device=eval_device,\n",
    "    max_batches=max_eval_batches,\n",
    "    auto_threshold=auto_threshold,\n",
    "    threshold_candidates=threshold_candidates,\n",
    "    threshold_metric=threshold_metric,\n",
    " )\n",
    "best_threshold = evaluation_summary.metrics.get(\"best_threshold\", {}).get(\"value\", threshold_candidates[0])\n",
    "print(\"Aggregate metrics (threshold {:.2f}):\".format(best_threshold))\n",
    "from pprint import pprint\n",
    "pprint({k: v for k, v in evaluation_summary.metrics.items() if k in {\"loss\", \"dice\", \"iou\", \"precision\", \"recall\", \"f1\"}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485924ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nConfusion matrix (rows=actual clean/tampered, cols=predicted clean/tampered):\")\n",
    "if pd is not None:\n",
    "    display(pd.DataFrame(\n",
    "        evaluation_summary.confusion_matrix,\n",
    "        index=[\"Actual clean\", \"Actual tampered\"],\n",
    "        columns=[\"Pred clean\", \"Pred tampered\"],\n",
    "    ))\n",
    "else:\n",
    "    print(evaluation_summary.confusion_matrix)\n",
    "threshold_table = evaluation_summary.metrics.get(\"thresholds\", {})\n",
    "if pd is not None and threshold_table:\n",
    "    display(pd.DataFrame(threshold_table).T.sort_index())\n",
    "print(\"Best threshold ({}): {:.2f}\".format(threshold_metric, best_threshold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f4c84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_preview_samples = 10\n",
    "preview_threshold = best_threshold if \"best_threshold\" in locals() else 0.5\n",
    "preview_samples = collect_visual_samples(\n",
    "    model=model,\n",
    "    train_config=trained_config,\n",
    "    split=evaluation_split,\n",
    "    num_samples=num_preview_samples,\n",
    "    device=eval_device,\n",
    "    threshold=preview_threshold,\n",
    " )\n",
    "columns = [\"image\", \"ground_truth\", \"prediction\", \"overlay\"]\n",
    "rows = len(preview_samples)\n",
    "if rows == 0:\n",
    "    raise RuntimeError(\"No samples with ground-truth masks were found in the requested split.\")\n",
    "fig, axes = plt.subplots(rows, len(columns), figsize=(15, 3 * rows))\n",
    "if rows == 1:\n",
    "    axes = np.expand_dims(axes, axis=0)\n",
    "for row_idx, sample in enumerate(preview_samples):\n",
    "    for col_idx, key in enumerate(columns):\n",
    "        axes[row_idx, col_idx].imshow(sample[key], cmap=\"gray\" if key in {\"ground_truth\", \"prediction\"} else None)\n",
    "        axes[row_idx, col_idx].set_title(f\"{key.replace('_', ' ').title()} #{row_idx + 1}\")\n",
    "        axes[row_idx, col_idx].axis(\"off\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f14a0c",
   "metadata": {},
   "source": [
    "### Single Image Inferencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135f2143",
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "from PIL import Image, ImageOps\n",
    "try:\n",
    "    from google.colab import files as colab_files\n",
    "except ImportError:\n",
    "    colab_files = None\n",
    "def _predict_image_array(image_arr: np.ndarray, checkpoint_path: Path, threshold: float) -> np.ndarray:\n",
    "    from model.hybrid_forgery_detector import HybridForgeryDetector\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=\"cpu\")\n",
    "    cfg = HybridForgeryConfig(**checkpoint[\"config\"][\"model_config\"])\n",
    "    device = eval_device\n",
    "    model = HybridForgeryDetector(cfg).to(device)\n",
    "    model.load_state_dict(checkpoint[\"model_state\"])\n",
    "    model.eval()\n",
    "    tensor = torch.from_numpy(image_arr.transpose(2, 0, 1)).unsqueeze(0).to(device)\n",
    "    zero_noise = torch.zeros(1, 3, tensor.shape[-2], tensor.shape[-1], device=device)\n",
    "    noise_inputs = {\"residual\": zero_noise}\n",
    "    with torch.no_grad():\n",
    "        mask = model.predict_mask(tensor, threshold=threshold, noise_features=noise_inputs)\n",
    "    return mask.squeeze().cpu().numpy()\n",
    "def _load_uploaded_image() -> tuple[Image.Image, str]:\n",
    "    if USE_COLAB and colab_files is not None:\n",
    "        uploaded = colab_files.upload()\n",
    "        if not uploaded:\n",
    "            raise ValueError(\"No file uploaded. Please select an image.\")\n",
    "        name, data = next(iter(uploaded.items()))\n",
    "        return Image.open(BytesIO(data)).convert(\"RGB\"), name\n",
    "    local_image_path = Path(\"./REPLACE_WITH_IMAGE.jpg\")\n",
    "    if \"REPLACE_WITH_IMAGE\" in str(local_image_path):\n",
    "        raise ValueError(\"Set local_image_path to an actual image path when running outside Colab.\")\n",
    "    if not local_image_path.exists():\n",
    "        raise FileNotFoundError(f\"Local image not found: {local_image_path}\")\n",
    "    return Image.open(local_image_path).convert(\"RGB\"), str(local_image_path)\n",
    "uploaded_image, uploaded_label = _load_uploaded_image()\n",
    "original_image = uploaded_image.copy()\n",
    "try:\n",
    "    resample_mode = Image.Resampling.BICUBIC\n",
    "except AttributeError:\n",
    "    resample_mode = Image.BICUBIC\n",
    "target_hw = (trained_config.target_size, trained_config.target_size)\n",
    "resized_image = ImageOps.fit(uploaded_image, target_hw, method=resample_mode)\n",
    "normalized = np.array(resized_image, dtype=np.float32) / 255.0\n",
    "checkpoint_for_single = checkpoint_path\n",
    "threshold_for_single = best_threshold\n",
    "pred_mask = _predict_image_array(normalized, checkpoint_for_single, threshold_for_single)\n",
    "fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
    "axes[0].imshow(original_image)\n",
    "axes[0].set_title(f\"Original ({uploaded_label})\")\n",
    "axes[0].axis(\"off\")\n",
    "axes[1].imshow(resized_image)\n",
    "axes[1].set_title(\"Resized\")\n",
    "axes[1].axis(\"off\")\n",
    "axes[2].imshow(pred_mask, cmap=\"magma\")\n",
    "axes[2].set_title(f\"Prediction (thr={threshold_for_single:.2f})\")\n",
    "axes[2].axis(\"off\")\n",
    "plt.tight_layout()\n",
    "pred_mask.shape"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

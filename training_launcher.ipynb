{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd80e778",
   "metadata": {},
   "source": [
    "# Hybrid Forgery Training + Evaluation\n",
    "This notebook lets you tune every training hyperparameter, toggle ablation flags, and launch `run_training` with tqdm progress bars. After training, reuse the same configuration to load checkpoints, compute metrics (Dice/IoU/precision/recall/F1 + confusion matrix), and visualize 10 qualitative test samples with image / ground-truth / prediction / overlay columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4710adc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from copy import deepcopy\n",
    "from dataclasses import asdict\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "try:\n",
    "    import pandas as pd\n",
    "except ImportError:\n",
    "    pd = None\n",
    "\n",
    "from train import TrainConfig, run_training\n",
    "from model.hybrid_forgery_detector import HybridForgeryConfig\n",
    "from evaluation.eval_utils import (\n",
    "    collect_visual_samples,\n",
    "    evaluate_split,\n",
    "    load_model_from_checkpoint,\n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9e78fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_train_cfg = TrainConfig()\n",
    "default_model_cfg = HybridForgeryConfig()\n",
    "print(\"Default TrainConfig:\")\n",
    "pprint(asdict(default_train_cfg))\n",
    "print(\"Default HybridForgeryConfig:\")\n",
    "pprint(asdict(default_model_cfg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec2b9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_config = TrainConfig(\n",
    "    prepared_root=\"prepared/CASIA2\",\n",
    "    train_split=\"train\",\n",
    "    val_split=\"val\",\n",
    "    target_size=128,\n",
    "    batch_size=8,\n",
    "    num_epochs=10,\n",
    "    learning_rate=1e-4,\n",
    "    weight_decay=1e-2,\n",
    "    grad_clip_norm=1.0,\n",
    "    log_interval=10,\n",
    "    checkpoint_dir=\"checkpoints\",\n",
    "    checkpoint_interval=1,\n",
    "    save_best_only=True,\n",
    "    use_amp=True,\n",
    "    resume_from=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf70f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_config.model_config = HybridForgeryConfig(\n",
    "    use_efficientnet=True,\n",
    "    use_swin=True,\n",
    "    use_segformer=False,\n",
    "    use_unet_decoder=True,\n",
    "    use_skip_connections=True,\n",
    "    pretrained_backbones=True,\n",
    "    fused_channels=256,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50613f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Resolved device:\", train_config.resolved_device())\n",
    "print(\"TrainConfig overrides:\")\n",
    "pprint(asdict(train_config))\n",
    "print(\"HybridForgeryConfig overrides:\")\n",
    "pprint(asdict(train_config.model_config))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c80516",
   "metadata": {},
   "source": [
    "### Optional Dry Run\n",
    "Flip the flag in the next cell to execute a 1-epoch, few-batch sanity check (uses `max_train_batches` / `max_val_batches`) before kicking off the full training run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2712f6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ENABLE_DRY_RUN = False  # flip to True to quickly verify data -> model -> optimizer plumbing\n",
    "if ENABLE_DRY_RUN:\n",
    "    dry_run_config = deepcopy(train_config)\n",
    "    dry_run_config.num_epochs = 1\n",
    "    dry_run_config.batch_size = min(2, train_config.batch_size)\n",
    "    dry_run_config.max_train_batches = 1\n",
    "    dry_run_config.max_val_batches = 1\n",
    "    dry_run_config.checkpoint_dir = str(Path(train_config.checkpoint_dir) / \"dry_run\")\n",
    "    print(\"Dry run settings:\", {\n",
    "        \"num_epochs\": dry_run_config.num_epochs,\n",
    "        \"batch_size\": dry_run_config.batch_size,\n",
    "        \"max_train_batches\": dry_run_config.max_train_batches,\n",
    "        \"max_val_batches\": dry_run_config.max_val_batches,\n",
    "        \"checkpoint_dir\": dry_run_config.checkpoint_dir,\n",
    "    })\n",
    "    dry_run_history = run_training(dry_run_config)\n",
    "else:\n",
    "    print(\"Dry run skipped. Set ENABLE_DRY_RUN = True to execute the smoke test.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67257c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = run_training(train_config)\n",
    "history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba09d27",
   "metadata": {},
   "source": [
    "## Evaluation, Samples, and Ablations\n",
    "Use the helpers below to load a checkpoint, compute aggregate metrics + confusion matrix on any split, and visualize 10 qualitative test samples aligned as image / ground-truth / prediction / overlay columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ac3a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = Path(\"checkpoints/best.pt\")\n",
    "evaluation_split = \"test\"\n",
    "ablation_label = f\"{checkpoint_path.stem}\"\n",
    "eval_device = train_config.resolved_device()\n",
    "max_eval_batches = None\n",
    "checkpoint_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87e4638",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, trained_config = load_model_from_checkpoint(checkpoint_path, device=eval_device)\n",
    "evaluation_summary = evaluate_split(\n",
    "    model=model,\n",
    "    train_config=trained_config,\n",
    "    split=evaluation_split,\n",
    "    batch_size=trained_config.batch_size,\n",
    "    device=eval_device,\n",
    "    max_batches=max_eval_batches,\n",
    " )\n",
    "\n",
    "print(\"Aggregate metrics:\")\n",
    "pprint(evaluation_summary.metrics)\n",
    "print(\"\\nConfusion matrix (rows=actual clean/tampered, cols=predicted clean/tampered):\")\n",
    "if pd is not None:\n",
    "    display(pd.DataFrame(\n",
    "        evaluation_summary.confusion_matrix,\n",
    "        index=[\"Actual clean\", \"Actual tampered\"],\n",
    "        columns=[\"Pred clean\", \"Pred tampered\"],\n",
    "    ))\n",
    "else:\n",
    "    print(evaluation_summary.confusion_matrix)\n",
    "\n",
    "if \"ablation_results\" not in globals():\n",
    "    ablation_results = []\n",
    "\n",
    "ablation_results.append({\n",
    "    \"label\": ablation_label,\n",
    "    **evaluation_summary.metrics,\n",
    "})\n",
    "if pd is not None:\n",
    "    display(pd.DataFrame(ablation_results))\n",
    "else:\n",
    "    print(ablation_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9acf02",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_preview_samples = 10\n",
    "preview_samples = collect_visual_samples(\n",
    "    model=model,\n",
    "    train_config=trained_config,\n",
    "    split=evaluation_split,\n",
    "    num_samples=num_preview_samples,\n",
    "    device=eval_device,\n",
    " )\n",
    "\n",
    "columns = [\"image\", \"ground_truth\", \"prediction\", \"overlay\"]\n",
    "rows = len(preview_samples)\n",
    "if rows == 0:\n",
    "    raise RuntimeError(\"No samples with ground-truth masks were found in the requested split.\")\n",
    "fig, axes = plt.subplots(rows, len(columns), figsize=(15, 3 * rows))\n",
    "if rows == 1:\n",
    "    axes = np.expand_dims(axes, axis=0)\n",
    "for row_idx, sample in enumerate(preview_samples):\n",
    "    for col_idx, key in enumerate(columns):\n",
    "        axes[row_idx, col_idx].imshow(sample[key], cmap=\"gray\" if key in {\"ground_truth\", \"prediction\"} else None)\n",
    "        axes[row_idx, col_idx].set_title(f\"{key.replace('_', ' ').title()} #{row_idx + 1}\")\n",
    "        axes[row_idx, col_idx].axis(\"off\")\n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lifd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
